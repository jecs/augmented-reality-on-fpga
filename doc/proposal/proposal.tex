\documentclass{article}

\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{mathtools}

\begin{document}
\title{Project Proposal\\Augmented Reality Image Processing System}
\author{Logan P. Williams \& Jos\'{e} E. Cruz Serrall\'{e}s}
\date{November 03, 2011}
\maketitle

\section{Abstract}
% Summary of what our project will do; could be called "Introduction", "Summary of Operation", etc.

\section{Top-Level Block Diagram}
% simply the image of our block diagram; let's wrap it with a \begin{figure}\end{figure} and a \centering to make it look nice

\section{Submodules \& Division of Labor}
% 1) inputs & outputs
% 2) some indication of its complexity and level of performance
%	a) number and type of arithmetic operations
%	b) size of internal memories
%	c) required throughput
%	etc.
% 3) how the module will be tested
% 4) who will be writing the module
\subsection{NTSC Capture}
% Logan

\subsection{ZBT Memory}
% Jose
The ZBT Memory module stores four 640x480 images in ZBT RAM. ZBT RAM was chosen instead of BRAM because the data in four 640x480 RGB images vastly exceeds our BRAM capacity. These three images will be (1) the image that is currently being captured (referred to as "capturing image"), (2) the image that was just captured (called " image"), (3) the image that was previously displayed (called "displayed image"). The inputs to ZBT Memory are (1) the next captured image pixel, (2) the next read processed image pixel index, (3) the next written processed image pixel and (4) pixel index, and (5) the next read displayed image pixel. The outputs of ZBT Memory are (1) the read processed image pixel, (2) the read displayed image pixel, (3) the starting index of the 

\subsection{Object Recognition}
% Logan

\subsection{ArbiLPF}
% Jose
The inputs to ArbiLPF are (1) the previously displayed image and (2) the four coordinates of the dotted frame as detected from the NTSC output of the camera in the Object Recognition module. AbiLPF calculates the maximal amount by which the skewing algorithm will shrink the image, which will be referred to as M. ArbiLPF then applies a two-dimensional low-pass filter to the image, with a radial cutoff frequency of \( \frac{\pi}{M} \), in order to avoid aliasing in the ArbiSkew module. The output of ArbiLPF is the low-passed version of this image.

Based on the downsampling factor M, the filter will select a set of coefficients from a lookup table and convolve the image values with these coefficients. This table of coefficients will correspond to the coefficients of 2D extrapolations of 1D FIR Parks-McClellan filters with cutoff frequencies of \( \frac{\pi}{M} \). Due to the limited number of multipliers on the FPGA, these 2D filters will be constrained to have at most 64 coefficients, which constrains the one-dimensional filters to have at most 8 coefficients. Due to these constraints, the ripple and transition width specifications of the 1D filters will have to be lax. The radial symmetry of these 2D filters will be exploited to reduce the number of required multiplications by a factor of 4, to at most 16 multiplications per color per pixel or 48 multiplications per pixel.

Given the constraint of at most 48 multiplications per pixel, ArbiLPF will have to perform at most 69,120,000 multiplications per image. Operating on two pixels every clock cycle, assuming a clock frequency of 25.175MHz, ArbiLPF will elapse 460,800 cycles per image. Therefore, with at most 96 multipliers, ArbiLPF will be able to process an image in roughly half an NTSC refresh period, giving the ArbiSkew module plenty of time to skew the output. ArbiSkew will also have to perform roughly eight additions per cycle, but the timing constraints imposed by these additions are negligible when compared to the multiplications.

ArbiLPF will be tested by crafting a testbench module that accepts an arbitrary 640x480 image and outputs the output of the filter. Initially, an image with an impulse at the center will be used, which ideally should cause the filter to output the filter coefficients that are used. As basic functionality is tested, more complicated images will be used. Eventually, complex images will be processed both with the testbench and with MATLAB and will be compared using the 2D Fourier plots of these two outputs.

\subsection{ArbiSkew}
% Logan

\subsection{VGA Write}
% Jose

\section{External Components}
% Jose

\section{List of Goals}
% A calendar-like view of what deadlines we'll set ourselves, when everything should be operational, etc. Maybe this could be collapsed into the submodules section

\end{document}
